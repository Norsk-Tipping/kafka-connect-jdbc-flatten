<?xml version="1.0" encoding="UTF-8"?>
<!--
  ~ Copyright 2018 Confluent Inc.
  ~
  ~ Licensed under the Confluent Community License (the "License"); you may not use
  ~ this file except in compliance with the License.  You may obtain a copy of the
  ~ License at
  ~
  ~ http://www.confluent.io/confluent-community-license
  ~
  ~ Unless required by applicable law or agreed to in writing, software
  ~ distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
  ~ WARRANTIES OF ANY KIND, either express or implied.  See the License for the
  ~ specific language governing permissions and limitations under the License.
  -->
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">

    <modelVersion>4.0.0</modelVersion>

    <parent>
        <groupId>io.confluent</groupId>
        <artifactId>common-parent</artifactId>
        <version>5.5.0</version>
    </parent>
    <pluginRepositories>
        <pluginRepository>
            <id>confluent</id>
            <name>Confluent</name>
            <url>${confluent.maven.repo}</url>
        </pluginRepository>
    </pluginRepositories>
    <version>5.5.1</version>

    <artifactId>kafka-connect-jdbc_flatten</artifactId>
    <packaging>jar</packaging>
    <name>kafka-connect-jdbc_flatten</name>
    <organization>
        <name>Norsk Tipping AS</name>
        <url>https://www.norsk-tipping.no/selskapet/engelsk</url>
    </organization>
    <url>https://www.norsk-tipping.no/selskapet/engelsk</url>
    <description>
       A Kafka Connect JDBC connector for copying data between databases and Kafka with a flattening feature to
        dereference arrays and maps into seperate target tables.
    </description>

    <licenses>
        <license>
            <name>Confluent Community License</name>
            <url>http://www.confluent.io/confluent-community-license</url>
            <distribution>repo</distribution>
        </license>
    </licenses>

    <properties>
        <confluent.version>${project.version}</confluent.version>
        <derby.version>10.14.2.0</derby.version>
        <commons-io.version>2.7</commons-io.version>
        <kafka.connect.maven.plugin.version>0.11.1</kafka.connect.maven.plugin.version>
        <sqlite-jdbc.version>3.25.2</sqlite-jdbc.version>
        <postgresql.version>42.2.10</postgresql.version>
        <jtds.driver.version>1.3.1</jtds.driver.version>
        <licenses.name>Confluent Community License</licenses.name>
        <licenses.version>${project.version}</licenses.version>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <project.package.home>target/${project.artifactId}-${project.version}-package</project.package.home>
        <confluent.maven.repo>http://packages.confluent.io/maven/</confluent.maven.repo>
    </properties>

    <scm>
        <url>https://github.com/gertschouten/kafka-connect-jdbc-flatten</url>
    </scm>

    <repositories>
        <repository>
            <id>confluent</id>
            <name>Confluent</name>
            <url>${confluent.maven.repo}</url>
        </repository>
    </repositories>

    <dependencies>
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>connect-api</artifactId>
            <scope>provided</scope>
        </dependency>

         <!-- JDBC drivers, only included in runtime so they get packaged -->
        <dependency>
            <groupId>org.xerial</groupId>
            <artifactId>sqlite-jdbc</artifactId>
            <version>${sqlite-jdbc.version}</version>
            <scope>runtime</scope>
        </dependency>
        <dependency>
            <groupId>org.postgresql</groupId>
            <artifactId>postgresql</artifactId>
            <version>${postgresql.version}</version>
            <scope>runtime</scope>
        </dependency>
        <dependency>
            <groupId>net.sourceforge.jtds</groupId>
            <artifactId>jtds</artifactId>
            <version>${jtds.driver.version}</version>
            <scope>runtime</scope>
        </dependency>

        <dependency>
            <groupId>junit</groupId>
            <artifactId>junit</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.easymock</groupId>
            <artifactId>easymock</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.powermock</groupId>
            <artifactId>powermock-module-junit4</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.powermock</groupId>
            <artifactId>powermock-api-easymock</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.derby</groupId>
            <artifactId>derby</artifactId>
            <version>${derby.version}</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>commons-io</groupId>
            <artifactId>commons-io</artifactId>
            <version>${commons-io.version}</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.mockito</groupId>
            <artifactId>mockito-all</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-log4j12</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.sourcelab</groupId>
            <artifactId>kafka-connect-client</artifactId>
            <version>2.1.0</version>
            <scope>test</scope>
            <exclusions>
                <exclusion>
                    <groupId>org.apache.logging.log4j</groupId>
                    <artifactId>log4j-slf4j-impl</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>connect-api</artifactId>
            <version>2.5.0</version>
        </dependency>
        <dependency>
            <groupId>com.codahale.metrics</groupId>
            <artifactId>metrics-core</artifactId>
            <version>3.0.2</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>io.confluent</groupId>
            <artifactId>common-utils</artifactId>
            <version>5.5.0</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.avro</groupId>
            <artifactId>avro</artifactId>
            <version>1.9.2</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>io.confluent</groupId>
            <artifactId>kafka-avro-serializer</artifactId>
            <version>5.5.0</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>com.google.guava</groupId>
            <artifactId>guava</artifactId>
            <version>29.0-jre</version>
        </dependency>
        <dependency>
            <groupId>org.javatuples</groupId>
            <artifactId>javatuples</artifactId>
            <version>1.2</version>
        </dependency>
        <dependency>
            <groupId>io.zonky.test</groupId>
            <artifactId>embedded-postgres</artifactId>
            <version>1.2.6</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>ch.vorburger.mariaDB4j</groupId>
            <artifactId>mariaDB4j</artifactId>
            <version>2.4.0</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.mariadb.jdbc</groupId>
            <artifactId>mariadb-java-client</artifactId>
            <version>2.5.3</version>
            <scope>test</scope>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <inherited>true</inherited>
                <configuration>
                    <compilerArgs>
                        <arg>-Xlint:all</arg>
                        <!--<arg>-Werror</arg>-->
                    </compilerArgs>
                </configuration>
            </plugin>
            <plugin>
                <groupId>io.confluent</groupId>
                <version>${kafka.connect.maven.plugin.version}</version>
                <artifactId>kafka-connect-maven-plugin</artifactId>
                <executions>
                    <execution>
                        <goals>
                            <goal>kafka-connect</goal>
                        </goals>
                        <configuration>
                            <title>Kafka Connect JDBC with Flatten Feature</title>
                            <documentationUrl>https://github.com/gertschouten/kafka-connect-jdbc-flatten</documentationUrl>
                            <description>
                                This connector is an extension to the existing Confluent JDBC connector.

                                With the flattening feature enabled, maps and arrays will be dereferenced and written to seperate target tables.

                                The JDBC source and sink connectors allow you to exchange data between relational databases and Kafka.

                                The JDBC source connector allows you to import data from any relational database with a JDBC driver into Kafka topics. By using JDBC, this connector can support a wide variety of databases without requiring custom code for each one.

                                Data is loaded by periodically executing a SQL query and creating an output record for each row in the result set. By default, all tables in a database are copied, each to its own output topic. The database is monitored for new or deleted tables and adapts automatically. When copying data from a table, the connector can load only new or modified rows by specifying which columns should be used to detect new or modified data.

                                The JDBC sink connector allows you to export data from Kafka topics to any relational database with a JDBC driver. By using JDBC, this connector can support a wide variety of databases without requiring a dedicated connector for each one. The connector polls data from Kafka to write to the database based on the topics subscription. It is possible to achieve idempotent writes with upserts. Auto-creation of tables, and limited auto-evolution is also supported.
                            </description>
                            <logo>logos/jdbc_flatten.png</logo>

                            <ownerUsername>norsktipping</ownerUsername>
                            <ownerType>organization</ownerType>
                            <ownerName>Norsk Tipping AS</ownerName>
                            <ownerUrl>https://www.norsk-tipping.no/selskapet/engelsk</ownerUrl>
                            <ownerLogo>logos/nt.png</ownerLogo>

                            <componentTypes>
                                <componentType>sink</componentType>
                                <componentType>source</componentType>
                            </componentTypes>

                            <tags>
                                <tag>jdbc</tag>
                                <tag>database</tag>
                                <tag>dbms</tag>
                                <tag>rdbms</tag>
                                <tag>sql</tag>
                                <tag>mysql</tag>
                                <tag>postgresql</tag>
                                <tag>oracle</tag>
                                <tag>sql server</tag>
                                <tag>db2</tag>
                                <tag>sybase</tag>
                                <tag>vertica</tag>
                                <tag>sap hana</tag>
                                <tag>derby</tag>
                                <tag>sqlite</tag>
                                <tag>flatten</tag>
                            </tags>

                            <confluentControlCenterIntegration>true</confluentControlCenterIntegration>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-failsafe-plugin</artifactId>
                <executions>
                    <execution>
                        <!--normal integration tests should not run the memory-restricted tests -->
                        <id>integration-test</id>
                        <configuration>
                            <excludes>
                                <exclude>**/*OOM*.java</exclude>
                            </excludes>
                        </configuration>
                    </execution>
                    <execution>
                        <id>integration-test-memory-restricted</id>
                        <goals>
                            <goal>integration-test</goal>
                        </goals>
                        <configuration>
                            <!-- out-of-memory tests should have a restricted heap size-->
                            <argLine>@{argLine} -Djava.awt.headless=true -Xmx128M</argLine>
                            <includes>
                                <include>**/*OOM*.java</include>
                            </includes>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-checkstyle-plugin</artifactId>
                <executions>
                    <execution>
                        <id>validate</id>
                        <!--<phase>validate</phase>-->
                        <phase>none</phase>
                        <configuration>
                            <suppressionsLocation>checkstyle/suppressions.xml</suppressionsLocation>
                        </configuration>
                        <goals>
                            <goal>check</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-shade-plugin</artifactId>
                <version>3.2.1</version>
                <executions>
                    <execution>
                        <phase>package</phase>
                        <goals>
                            <goal>shade</goal>
                        </goals>
                        <configuration>
                            <transformers>
                                <transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">
                                    <mainClass>no.norsktipping.kafka.connect.jdbc.connector.JdbcSinkConnector_Flatten</mainClass>
                                </transformer>
                            </transformers>
                            <finalName>norsktipping-${project.artifactId}-${project.version}</finalName>
                            <outputDirectory>target</outputDirectory>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-jar-plugin</artifactId>
                <executions>
                    <execution>
                        <id>test-jar</id>
                        <phase>none</phase>
                        <configuration>
                            <finalName>unwanted</finalName>
                            <classifier>unwanted</classifier>
                        </configuration>
                    </execution>
                    <execution>
                        <id>default-jar</id>
                        <phase>none</phase>
                        <configuration>
                            <finalName>unwanted</finalName>
                            <classifier>unwanted</classifier>
                        </configuration>
                    </execution>
                    <execution>
                        <id>default</id>
                        <phase>none</phase>
                        <configuration>
                            <finalName>unwanted</finalName>
                            <classifier>unwanted</classifier>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-install-plugin</artifactId>
                <version>${maven-install-plugin.version}</version>
                <inherited>false</inherited>
                <executions>
                    <execution>
                        <id>custom-install</id>
                        <goals>
                            <goal>install-file</goal>
                        </goals>
                        <phase>none</phase>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.codehaus.mojo</groupId>
                <artifactId>exec-maven-plugin</artifactId>
                <version>1.2.1</version>
            </plugin>
        </plugins>
        <resources>
            <resource>
                <directory>src/main/resources</directory>
                <filtering>true</filtering>
            </resource>
        </resources>
    </build>
</project>
